<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <title>AI Drowsiness Detection</title>
    
    <!-- All CSS is in this style tag -->
    <style>
        :root {
            --primary-color: #0d1b2a;
            --secondary-color: #1b263b;
            --accent-color: #415a77;
            --text-color: #e0e1dd;
            --highlight-color: #778da9;
            --alert-color: #e63946;
            --success-color: #2ecc71;
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        html, body {
            height: 100%;
            width: 100%;
            overflow: hidden;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Open Sans', 'Helvetica Neue', sans-serif;
            background-color: var(--primary-color);
            color: var(--text-color);
            display: flex;
            justify-content: center;
            align-items: center;
            -webkit-tap-highlight-color: transparent; /* Disable tap highlight on mobile */
        }

        #three-bg {
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            z-index: -1;
        }

        .app-wrapper {
            position: relative;
            z-index: 10;
            width: clamp(300px, 90vw, 540px);
            padding: 2rem;
            background-color: rgba(27, 38, 59, 0.85);
            backdrop-filter: blur(10px);
            border-radius: 20px;
            border: 1px solid var(--accent-color);
            box-shadow: 0 10px 30px rgba(0, 0, 0, 0.3);
            text-align: center;
        }
        
        #permission-overlay {
            display: flex;
            flex-direction: column;
            align-items: center;
            gap: 1.5rem;
        }
        
        #main-container {
            display: none; /* Hidden by default, shown after permission */
            flex-direction: column;
            align-items: center;
        }

        h1 {
            font-size: clamp(1.5rem, 6vw, 2.5rem);
            color: var(--text-color);
            margin-bottom: 0.5rem;
            letter-spacing: 2px;
            text-shadow: 0 0 10px var(--highlight-color);
        }
        
        p.description {
            font-size: clamp(0.9rem, 3vw, 1rem);
            color: var(--highlight-color);
            margin-bottom: 1rem;
        }

        .video-container {
            position: relative;
            width: 100%;
            padding-top: 75%; /* 4:3 Aspect Ratio */
            margin-top: 1rem;
            border-radius: 10px;
            overflow: hidden;
            border: 2px solid var(--accent-color);
            background-color: #000;
        }

        #video, #overlayCanvas {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            transform: scaleX(-1); /* Mirror effect */
        }
        
        #overlayCanvas {
            z-index: 11;
        }

        .controls {
            margin-top: 1.5rem;
            display: flex;
            flex-direction: column;
            align-items: center;
            gap: 1rem;
            width: 100%;
        }

        .button {
            padding: 14px 28px;
            font-size: 1.1rem;
            font-weight: bold;
            color: var(--text-color);
            background-color: var(--highlight-color);
            border: none;
            border-radius: 8px;
            cursor: pointer;
            transition: all 0.3s ease;
            box-shadow: 0 4px 15px rgba(0,0,0,0.2);
            width: 100%;
            -webkit-appearance: none;
        }

        .button:hover:not(:disabled) {
            background-color: var(--accent-color);
            transform: translateY(-2px);
        }

        .button:disabled {
            background-color: var(--secondary-color);
            cursor: not-allowed;
            transform: none;
            opacity: 0.7;
        }

        .status-container {
            display: flex;
            justify-content: space-around;
            width: 100%;
            background-color: var(--secondary-color);
            padding: 0.75rem;
            border-radius: 8px;
        }
        
        .status-box {
            display: flex;
            flex-direction: column;
        }

        .status-box p {
            font-size: 1rem;
            margin: 0;
            font-weight: 500;
        }

        .status-box .label {
            font-size: 0.8rem;
            color: var(--highlight-color);
            text-transform: uppercase;
        }

        #status.awake { color: var(--success-color); }
        #status.drowsy { color: var(--alert-color); font-weight: bold; }

        #alert-overlay {
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background-color: rgba(230, 57, 70, 0.7);
            display: none; /* Initially hidden */
            justify-content: center;
            align-items: center;
            z-index: 100;
            opacity: 0;
        }

        #alert-message {
            color: white;
            font-size: clamp(2rem, 10vw, 4rem);
            font-weight: bold;
            text-shadow: 0 0 20px rgba(0,0,0,0.5);
            transform: scale(0.5);
        }
    </style>
</head>
<body>

    <!-- Three.js Background Canvas -->
    <div id="three-bg"></div>

    <!-- Main Application Container -->
    <div class="app-wrapper">
        
        <!-- Step 1: Permission Screen -->
        <div id="permission-overlay">
            <h1>Stay Alert</h1>
            <p class="description">This app uses your camera to detect drowsiness in real-time. Your privacy is protected as no video data leaves your device.</p>
            <button id="permissionButton" class="button">Grant Camera Access</button>
        </div>

        <!-- Step 2: Main App (Initially Hidden) -->
        <div id="main-container">
            <h1>AI Drowsiness Detection</h1>
            <div class="video-container">
                <video id="video" autoplay playsinline muted></video>
                <canvas id="overlayCanvas"></canvas>
            </div>
            <div class="controls">
                <div class="status-container">
                    <div class="status-box">
                        <p id="status" class="awake">AWAKE</p>
                        <span class="label">Status</span>
                    </div>
                     <div class="status-box">
                        <p id="earValue">0.00</p>
                        <span class="label">Eye Ratio</span>
                    </div>
                </div>
                <button id="startButton" class="button">Start Detection</button>
            </div>
        </div>
    </div>

    <!-- Alert Overlay -->
    <div id="alert-overlay">
        <div id="alert-message">WAKE UP!</div>
    </div>
    
    <!-- Audio alarm linked from an online source (Pixabay) -->
    <audio id="alertSound" src="https://cdn.pixabay.com/download/audio/2021/08/04/audio_c683f082e7.mp3" preload="auto"></audio>

    <!-- All JavaScript is in this script tag -->
    <script type="module">
        // Import necessary libraries from CDNs
        import * as THREE from 'https://cdn.skypack.dev/three@0.132.2';
        import { gsap } from 'https://cdn.skypack.dev/gsap@3.9.1';
        import 'https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-core';
        import 'https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-backend-webgl';
        import * as faceLandmarksDetection from 'https://cdn.jsdelivr.net/npm/@tensorflow-models/face-landmarks-detection';

        // --- DOM Elements ---
        const permissionOverlay = document.getElementById('permission-overlay');
        const permissionButton = document.getElementById('permissionButton');
        const mainContainer = document.getElementById('main-container');
        const video = document.getElementById('video');
        const startButton = document.getElementById('startButton');
        const statusEl = document.getElementById('status');
        const earValueEl = document.getElementById('earValue');
        const alertOverlay = document.getElementById('alert-overlay');
        const alertSound = document.getElementById('alertSound');
        const overlayCanvas = document.getElementById('overlayCanvas');
        const ctx = overlayCanvas.getContext('2d');

        // --- Detection Constants ---
        const EAR_THRESHOLD = 0.21;
        const CONSECUTIVE_FRAMES = 20;

        // --- State Variables ---
        let detector;
        let detectionInterval;
        let closedEyeFrames = 0;
        let isAlerting = false;
        let isRunning = false;
        let modelReady = false;

        // --- Three.js Background Setup ---
        const scene = new THREE.Scene();
        const camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 1000);
        const renderer = new THREE.WebGLRenderer({ antialias: true });
        renderer.setSize(window.innerWidth, window.innerHeight);
        document.getElementById('three-bg').appendChild(renderer.domElement);

        // NEW: Icosahedron Geometry
        const geometry = new THREE.IcosahedronGeometry(1.5, 0); // Radius 1.5, detail 0
        const material = new THREE.MeshBasicMaterial({ color: 0x778da9, wireframe: true });
        const icosahedron = new THREE.Mesh(geometry, material);
        scene.add(icosahedron);
        
        camera.position.z = 3;

        window.addEventListener('resize', () => {
            renderer.setSize(window.innerWidth, window.innerHeight);
            camera.aspect = window.innerWidth / window.innerHeight;
            camera.updateProjectionMatrix();
        });

        function animate3D() {
            requestAnimationFrame(animate3D);
            icosahedron.rotation.y += 0.001;
            icosahedron.rotation.x += 0.001;
            renderer.render(scene, camera);
        }
        animate3D();

        // --- Main Application Logic ---

        /**
         * Initializes the ML model.
         */
        async function initializeModel() {
            try {
                const model = faceLandmarksDetection.SupportedModels.MediaPipeFaceMesh;
                const detectorConfig = {
                    runtime: 'mediapipe',
                    solutionPath: 'https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh',
                };
                detector = await faceLandmarksDetection.createDetector(model, detectorConfig);
                modelReady = true;
                permissionButton.disabled = false;
                permissionButton.innerText = 'Grant Camera Access';
                console.log("Model loaded successfully.");
            } catch (error) {
                console.error("Model initialization failed:", error);
                permissionButton.innerText = 'Error - Refresh';
                alert("Could not load the AI model. Please check your connection and refresh the page.");
            }
        }

        /**
         * Requests camera permission from the user.
         */
        async function requestCameraPermission() {
            try {
                permissionButton.disabled = true;
                permissionButton.innerText = 'Awaiting Permission...';
                
                const stream = await navigator.mediaDevices.getUserMedia({ video: true });
                // We got permission. Stop the track immediately. We'll start it again later.
                stream.getTracks().forEach(track => track.stop());
                
                // Animate the UI transition
                gsap.to(permissionOverlay, {
                    opacity: 0,
                    duration: 0.5,
                    onComplete: () => {
                        permissionOverlay.style.display = 'none';
                        mainContainer.style.display = 'flex';
                        gsap.from(mainContainer, { opacity: 0, duration: 0.5 });
                    }
                });

            } catch (err) {
                console.error("Camera access denied:", err);
                permissionButton.disabled = false;
                permissionButton.innerText = 'Grant Camera Access';
                alert("Camera permission is required. Please enable it in your browser settings and try again.");
            }
        }

        const calculateEAR = (eye) => {
            const A = Math.hypot(eye[1].x - eye[5].x, eye[1].y - eye[5].y);
            const B = Math.hypot(eye[2].x - eye[4].x, eye[2].y - eye[4].y);
            const C = Math.hypot(eye[0].x - eye[3].x, eye[0].y - eye[3].y);
            return (A + B) / (2.0 * C);
        };

        async function detectDrowsiness() {
            if (!detector || !isRunning) return;

            const faces = await detector.estimateFaces(video, { flipHorizontal: false });
            ctx.clearRect(0, 0, overlayCanvas.width, overlayCanvas.height);

            if (faces.length > 0) {
                const keypoints = faces[0].keypoints;
                const leftEyeIndices = [33, 160, 158, 133, 153, 144];
                const rightEyeIndices = [362, 385, 387, 263, 373, 380];
                
                const leftEye = leftEyeIndices.map(i => keypoints[i]);
                const rightEye = rightEyeIndices.map(i => keypoints[i]);

                const leftEAR = calculateEAR(leftEye);
                const rightEAR = calculateEAR(rightEye);
                const avgEAR = (leftEAR + rightEAR) / 2.0;
                
                earValueEl.innerText = avgEAR.toFixed(2);
                
                // Draw eye landmarks for visualization
                ctx.fillStyle = "rgba(119, 141, 169, 0.7)";
                [...leftEye, ...rightEye].forEach(point => {
                    ctx.beginPath();
                    ctx.arc(point.x, point.y, 2, 0, 2 * Math.PI);
                    ctx.fill();
                });

                if (avgEAR < EAR_THRESHOLD) {
                    closedEyeFrames++;
                } else {
                    closedEyeFrames = 0;
                    if (isAlerting) {
                        isAlerting = false;
                        gsap.to(alertOverlay, { display: 'none', opacity: 0, duration: 0.5 });
                        gsap.killTweensOf('#alert-message');
                        alertSound.pause();
                        alertSound.currentTime = 0;
                    }
                    statusEl.innerText = 'AWAKE';
                    statusEl.className = 'awake';
                }

                if (closedEyeFrames >= CONSECUTIVE_FRAMES && !isAlerting) {
                    isAlerting = true;
                    statusEl.innerText = 'DROWSY';
                    statusEl.className = 'drowsy';
                    triggerAlert();
                }
            } else {
                statusEl.innerText = 'NO FACE';
                statusEl.className = 'drowsy';
                earValueEl.innerText = 'N/A';
            }
        }
        
        function triggerAlert() {
            if (!isAlerting) return;
            alertSound.play();
            gsap.set(alertOverlay, { display: 'flex' });
            gsap.to(alertOverlay, { opacity: 1, duration: 0.5 });
            gsap.fromTo('#alert-message', 
                { scale: 0.5 }, 
                { scale: 1, duration: 0.3, ease: 'back.out(1.7)', yoyo: true, repeat: -1, repeatDelay: 0.5 }
            );
        }
        
        async function toggleDetection() {
            if (isRunning) {
                // Stop detection
                isRunning = false;
                clearInterval(detectionInterval);
                video.srcObject.getTracks().forEach(track => track.stop());
                video.srcObject = null;
                startButton.innerText = 'Start Detection';
                ctx.clearRect(0, 0, overlayCanvas.width, overlayCanvas.height);
                statusEl.innerText = 'INACTIVE';
                statusEl.className = '';
            } else {
                // Start detection
                try {
                    startButton.disabled = true;
                    startButton.innerText = 'Starting Camera...';

                    const stream = await navigator.mediaDevices.getUserMedia({
                        video: { width: 640, height: 480 },
                    });
                    video.srcObject = stream;
                    await new Promise(resolve => {
                        video.onloadedmetadata = () => {
                            overlayCanvas.width = video.videoWidth;
                            overlayCanvas.height = video.videoHeight;
                            resolve();
                        };
                    });
                    
                    isRunning = true;
                    detectionInterval = setInterval(detectDrowsiness, 1000 / 30); // ~30 FPS
                    startButton.innerText = 'Stop Detection';
                    startButton.disabled = false;
                    
                } catch(err) {
                    console.error("Error starting camera:", err);
                    alert("Could not start the camera. Please ensure it's not being used by another application.");
                    startButton.disabled = false;
                    startButton.innerText = 'Start Detection';
                }
            }
        }

        // --- Event Listeners & Initialization ---
        permissionButton.addEventListener('click', requestCameraPermission);
        startButton.addEventListener('click', toggleDetection);
        
        // Disable button until model is loaded
        permissionButton.disabled = true;
        permissionButton.innerText = 'Loading AI Model...';
        initializeModel();

    </script>
</body>
</html>

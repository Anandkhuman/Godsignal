<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Drowsiness Detection</title>
    
    <!-- All CSS is in this style tag -->
    <style>
        :root {
            --primary-color: #0d1b2a;
            --secondary-color: #1b263b;
            --accent-color: #415a77;
            --text-color: #e0e1dd;
            --highlight-color: #778da9;
            --alert-color: #e63946;
            --success-color: #2ecc71;
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Open Sans', 'Helvetica Neue', sans-serif;
            background-color: var(--primary-color);
            color: var(--text-color);
            overflow: hidden;
            display: flex;
            justify-content: center;
            align-items: center;
            height: 100vh;
        }

        #three-bg {
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            z-index: -1;
        }

        .container {
            position: relative;
            z-index: 10;
            display: flex;
            flex-direction: column;
            align-items: center;
            padding: 2rem;
            background-color: rgba(27, 38, 59, 0.85);
            backdrop-filter: blur(10px);
            border-radius: 20px;
            border: 1px solid var(--accent-color);
            box-shadow: 0 10px 30px rgba(0, 0, 0, 0.3);
            text-align: center;
            max-width: 90vw;
            width: 540px;
        }

        h1 {
            font-size: clamp(1.5rem, 5vw, 2.5rem);
            color: var(--text-color);
            margin-bottom: 0.5rem;
            letter-spacing: 2px;
            text-shadow: 0 0 10px var(--highlight-color);
        }

        .video-container {
            position: relative;
            width: 100%;
            padding-top: 75%; /* 4:3 Aspect Ratio */
            margin-top: 1rem;
            border-radius: 10px;
            overflow: hidden;
            border: 2px solid var(--accent-color);
            background-color: #000;
        }

        #video, #overlayCanvas {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            transform: scaleX(-1); /* Mirror effect */
        }
        
        #overlayCanvas {
            z-index: 11;
        }

        .controls {
            margin-top: 1.5rem;
            display: flex;
            flex-direction: column;
            align-items: center;
            gap: 1rem;
            width: 100%;
        }

        #startButton {
            padding: 12px 25px;
            font-size: 1.1rem;
            font-weight: bold;
            color: var(--text-color);
            background-color: var(--highlight-color);
            border: none;
            border-radius: 5px;
            cursor: pointer;
            transition: all 0.3s ease;
            box-shadow: 0 4px 15px rgba(0,0,0,0.2);
            width: 100%;
        }

        #startButton:hover:not(:disabled) {
            background-color: var(--accent-color);
            transform: translateY(-2px);
        }

        #startButton:disabled {
            background-color: var(--secondary-color);
            cursor: not-allowed;
            transform: none;
            opacity: 0.7;
        }

        .status-container {
            display: flex;
            justify-content: space-around;
            width: 100%;
            background-color: var(--secondary-color);
            padding: 0.75rem;
            border-radius: 8px;
        }
        
        .status-box {
            display: flex;
            flex-direction: column;
        }

        .status-box p {
            font-size: 1rem;
            margin: 0;
            font-weight: 500;
        }

        .status-box .label {
            font-size: 0.8rem;
            color: var(--highlight-color);
            text-transform: uppercase;
        }

        #status.awake { color: var(--success-color); }
        #status.drowsy { color: var(--alert-color); font-weight: bold; }

        #alert-overlay {
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background-color: rgba(230, 57, 70, 0.7);
            display: none; /* Initially hidden */
            justify-content: center;
            align-items: center;
            z-index: 100;
            opacity: 0;
        }

        #alert-message {
            color: white;
            font-size: clamp(2rem, 10vw, 4rem);
            font-weight: bold;
            text-shadow: 0 0 20px rgba(0,0,0,0.5);
            transform: scale(0.5);
        }
    </style>
</head>
<body>

    <!-- Three.js Background Canvas -->
    <div id="three-bg"></div>

    <!-- Main Application Container -->
    <div class="container">
        <h1>AI Drowsiness Detection</h1>
        
        <div class="video-container">
            <video id="video" autoplay playsinline muted></video>
            <canvas id="overlayCanvas"></canvas>
        </div>

        <div class="controls">
            <div class="status-container">
                <div class="status-box">
                    <p id="status" class="awake">AWAKE</p>
                    <span class="label">Status</span>
                </div>
                 <div class="status-box">
                    <p id="earValue">0.00</p>
                    <span class="label">Eye Ratio</span>
                </div>
            </div>
            <button id="startButton" disabled>Loading Model...</button>
        </div>
    </div>

    <!-- Alert Overlay -->
    <div id="alert-overlay">
        <div id="alert-message">WAKE UP!</div>
    </div>
    
    <!-- Audio alarm linked from an online source (Pixabay) -->
    <audio id="alertSound" src="https://cdn.pixabay.com/download/audio/2021/08/04/audio_c683f082e7.mp3" preload="auto"></audio>

    <!--
      This script tag uses type="module" to allow for ES6 imports.
      All libraries are loaded from trusted CDNs.
    -->
    <script type="module">
        // Import necessary libraries from CDNs
        import * as THREE from 'https://cdn.skypack.dev/three@0.132.2';
        import { gsap } from 'https://cdn.skypack.dev/gsap@3.9.1';
        import 'https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-core';
        import 'https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-backend-webgl';
        import * as faceLandmarksDetection from 'https://cdn.jsdelivr.net/npm/@tensorflow-models/face-landmarks-detection';

        // --- DOM Elements ---
        const video = document.getElementById('video');
        const startButton = document.getElementById('startButton');
        const statusEl = document.getElementById('status');
        const earValueEl = document.getElementById('earValue');
        const alertOverlay = document.getElementById('alert-overlay');
        const alertSound = document.getElementById('alertSound');
        const overlayCanvas = document.getElementById('overlayCanvas');
        const ctx = overlayCanvas.getContext('2d');

        // --- Detection Constants ---
        const EAR_THRESHOLD = 0.21; // Threshold for eye closure
        const CONSECUTIVE_FRAMES = 20; // Number of consecutive frames with closed eyes to trigger an alert

        // --- State Variables ---
        let detector;
        let detectionInterval;
        let closedEyeFrames = 0;
        let isAlerting = false;
        let isRunning = false;

        // --- Three.js Background Setup ---
        const scene = new THREE.Scene();
        const camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 1000);
        const renderer = new THREE.WebGLRenderer();
        renderer.setSize(window.innerWidth, window.innerHeight);
        document.getElementById('three-bg').appendChild(renderer.domElement);

        const particlesGeometry = new THREE.BufferGeometry();
        const particlesCount = 5000;
        const posArray = new Float32Array(particlesCount * 3);
        for (let i = 0; i < particlesCount * 3; i++) {
            posArray[i] = (Math.random() - 0.5) * 5;
        }
        particlesGeometry.setAttribute('position', new THREE.BufferAttribute(posArray, 3));
        const particlesMaterial = new THREE.PointsMaterial({ size: 0.005, color: 0x778da9 });
        const particlesMesh = new THREE.Points(particlesGeometry, particlesMaterial);
        scene.add(particlesMesh);
        camera.position.z = 2;

        window.addEventListener('resize', () => {
            renderer.setSize(window.innerWidth, window.innerHeight);
            camera.aspect = window.innerWidth / window.innerHeight;
            camera.updateProjectionMatrix();
        });

        function animate3D() {
            requestAnimationFrame(animate3D);
            particlesMesh.rotation.y += 0.0005;
            particlesMesh.rotation.x += 0.0005;
            renderer.render(scene, camera);
        }
        animate3D();

        // --- Main Application Logic ---

        /**
         * Initializes the ML model and webcam
         */
        async function main() {
            try {
                // Load the MediaPipe Face Landmark detection model.
                const model = faceLandmarksDetection.SupportedModels.MediaPipeFaceMesh;
                const detectorConfig = {
                    runtime: 'mediapipe',
                    solutionPath: 'https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh',
                };
                detector = await faceLandmarksDetection.createDetector(model, detectorConfig);

                startButton.innerText = 'Start Detection';
                startButton.disabled = false;
            } catch (error) {
                console.error("Initialization failed:", error);
                startButton.innerText = 'Error - Refresh';
                alert("Could not initialize the model or camera. Please refresh the page and grant permissions.");
            }
        }

        /**
         * Calculates the Eye Aspect Ratio (EAR)
         * @param {Array} eye - Array of eye landmark points
         */
        function calculateEAR(eye) {
            const A = Math.hypot(eye[1].x - eye[5].x, eye[1].y - eye[5].y);
            const B = Math.hypot(eye[2].x - eye[4].x, eye[2].y - eye[4].y);
            const C = Math.hypot(eye[0].x - eye[3].x, eye[0].y - eye[3].y);
            return (A + B) / (2.0 * C);
        }

        /**
         * Euclidean distance
         */
        const distance = (p1, p2) => Math.hypot(p1.x - p2.x, p1.y - p2.y);

        /**
         * Main detection loop
         */
        async function detectDrowsiness() {
            if (!detector || !isRunning) return;

            const faces = await detector.estimateFaces(video, { flipHorizontal: false });
            ctx.clearRect(0, 0, overlayCanvas.width, overlayCanvas.height);

            if (faces.length > 0) {
                const keypoints = faces[0].keypoints;
                
                // Landmark indices for eyes
                const leftEyeIndices = [33, 160, 158, 133, 153, 144];
                const rightEyeIndices = [362, 385, 387, 263, 373, 380];
                
                const leftEye = leftEyeIndices.map(i => keypoints[i]);
                const rightEye = rightEyeIndices.map(i => keypoints[i]);

                const leftEAR = calculateEAR(leftEye);
                const rightEAR = calculateEAR(rightEye);
                const avgEAR = (leftEAR + rightEAR) / 2.0;
                
                earValueEl.innerText = avgEAR.toFixed(2);
                
                // Draw eye landmarks for visualization
                drawEyeLandmarks(leftEye);
                drawEyeLandmarks(rightEye);

                if (avgEAR < EAR_THRESHOLD) {
                    closedEyeFrames++;
                } else {
                    closedEyeFrames = 0;
                    if (isAlerting) {
                        isAlerting = false;
                        gsap.to(alertOverlay, { display: 'none', opacity: 0, duration: 0.5 });
                        alertSound.pause();
                        alertSound.currentTime = 0;
                    }
                    statusEl.innerText = 'AWAKE';
                    statusEl.className = 'awake';
                }

                if (closedEyeFrames >= CONSECUTIVE_FRAMES && !isAlerting) {
                    isAlerting = true;
                    statusEl.innerText = 'DROWSY';
                    statusEl.className = 'drowsy';
                    triggerAlert();
                }

            } else {
                statusEl.innerText = 'NO FACE';
                statusEl.className = 'drowsy';
                earValueEl.innerText = 'N/A';
            }
        }
        
        function drawEyeLandmarks(eye) {
            ctx.fillStyle = "rgba(119, 141, 169, 0.7)"; // --highlight-color
            eye.forEach(point => {
                ctx.beginPath();
                ctx.arc(point.x, point.y, 2, 0, 2 * Math.PI);
                ctx.fill();
            });
        }
        
        /**
         * Triggers the visual and audio alert
         */
        function triggerAlert() {
            if (!isAlerting) return;
            alertSound.play();
            gsap.set(alertOverlay, { display: 'flex' });
            gsap.to(alertOverlay, { 
                opacity: 1, 
                duration: 0.5,
                onComplete: () => {
                    gsap.to('#alert-message', {
                        scale: 1,
                        duration: 0.3,
                        ease: 'back.out(1.7)',
                        yoyo: true,
                        repeat: -1,
                        repeatDelay: 0.5
                    });
                }
            });
        }
        
        /**
         * Starts or stops the detection process
         */
        async function toggleDetection() {
            if (isRunning) {
                // Stop detection
                isRunning = false;
                clearInterval(detectionInterval);
                video.srcObject.getTracks().forEach(track => track.stop());
                video.srcObject = null;
                startButton.innerText = 'Start Detection';
                gsap.to('.container', { scale: 1, duration: 0.3 });
                ctx.clearRect(0, 0, overlayCanvas.width, overlayCanvas.height);
            } else {
                // Start detection
                try {
                    const stream = await navigator.mediaDevices.getUserMedia({
                        video: { width: 640, height: 480 },
                    });
                    video.srcObject = stream;
                    await new Promise((resolve) => {
                        video.onloadedmetadata = () => {
                            overlayCanvas.width = video.videoWidth;
                            overlayCanvas.height = video.videoHeight;
                            resolve();
                        };
                    });
                    
                    isRunning = true;
                    detectionInterval = setInterval(detectDrowsiness, 1000 / 30); // 30 FPS
                    startButton.innerText = 'Stop Detection';
                    gsap.to('.container', { scale: 1.02, duration: 0.3 });
                    
                } catch(err) {
                    console.error("Camera access denied:", err);
                    alert("Camera access is required. Please allow camera access and try again.");
                }
            }
        }

        // --- Event Listeners ---
        startButton.addEventListener('click', toggleDetection);
        
        // --- Initialization ---
        main();

    </script>
</body>
</html>
